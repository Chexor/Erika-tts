# Erika TTS Project Overview

This directory contains a Python Text-to-Speech (TTS) project named "Erika TTS". It is a personalized wrapper around Kyutai's Pocket TTS library, offering a flexible solution for generating speech from text with both a web API and a command-line interface (CLI). A key feature is its ability to clone voices from provided audio prompts, which can be local files, HTTP/HTTPS URLs, or Hugging Face repository URLs.

## Main Technologies

*   **Python**: The core programming language.
*   **FastAPI**: Used for building the asynchronous web API.
*   **Typer**: Utilized for creating the intuitive command-line interface.
*   **Uvicorn**: Serves as the ASGI web server for the FastAPI application.
*   **PyTorch**: The underlying deep learning framework likely powering the `TTSModel` for speech synthesis.
*   **Hugging Face Hub**: Integrated for accessing and utilizing voice prompts from Hugging Face repositories.

## Building and Running

As this project appears to be primarily an installed Python package within a virtual environment, the "building" phase is typically handled during its installation. The following instructions detail how to run the web API or generate speech via the CLI.

### Activating the Virtual Environment

Before running any commands, ensure your Python virtual environment is activated:

*   **On Windows:**
    ```bash
    .\venv\Scripts\activate
    ```
*   **On Linux/macOS:**
    ```bash
    source venv/bin/activate
    ```

### Running the Web API

The web API allows for interactive TTS generation via a browser-based interface and programmatic access.

```bash
# Start the FastAPI server (ensure virtual environment is activated)
pocket-tts serve --host 0.0.0.0 --port 8000 --reload
```

*   **Interactive API Documentation**: Once the server is running, you can access the auto-generated OpenAPI (Swagger UI) documentation at `http://localhost:8000/docs`.
*   **Frontend Interface**: A basic frontend for interacting with the TTS service should be available at `http://localhost:8000/`.

The `/tts` endpoint accepts `POST` requests with `text` (the content to speak) and optional `voice_url` (URL to an audio prompt) or `voice_wav` (an uploaded WAV file) for voice cloning.

### Generating Speech via CLI

For direct speech generation to an audio file, use the `generate` command:

```bash
# Generate speech with default settings (ensure virtual environment is activated)
pocket-tts generate --text "Hello, this is a test from Erika TTS." --output-path my_output.wav

# Generate speech using a custom voice prompt and specific parameters
pocket-tts generate \
    --text "This is an example of a custom voice generated by the CLI." \
    --voice "path/to/your_custom_voice.wav" \
    --variant "b6369a24" \
    --temperature 0.8 \
    --output-path custom_voice_output.wav

# You can also use predefined voices or Hugging Face URLs:
pocket-tts generate --text "Using the Alba voice." --voice "alba" --output-path alba_voice.wav
pocket-tts generate --text "Generating with a Hugging Face voice." --voice "hf://user/repo/voice.wav" --output-path hf_voice.wav
```

**Common `generate` Options:**

*   `--text TEXT`: The text to convert to speech.
*   `--voice VOICE`: Path to an audio conditioning file (voice to clone), or a predefined voice name, or a URL (http://, https://, hf://). Default is "alba".
*   `--output-path PATH`: The file path to save the generated audio. Default is `./tts_output.wav`.
*   `--variant VARIANT`: Model signature to use. Default is "b6369a24".
*   `--temperature TEMPERATURE`: Temperature for generation (controls randomness). Default is 0.7.
*   `--lsd-decode-steps STEPS`: Number of generation steps. Default is 1.
*   `--device DEVICE`: The device to use for generation (e.g., "cpu", "cuda").

## Development Conventions

*   **Logging**: The project utilizes Python's standard `logging` module for output and debugging.
*   **CLI Argument Parsing**: `typer` is used for defining and parsing command-line arguments, providing a user-friendly CLI experience.
*   **Type Hinting**: `Annotated` from `typing_extensions` is employed for rich type hints, enhancing code clarity and maintainability.
*   **Core TTS Logic**: The central Text-to-Speech functionality is encapsulated within the `pocket_tts.models.tts_model.TTSModel` class.